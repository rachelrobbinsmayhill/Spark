{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afe5b9d8-bf25-4261-a87b-3f9e715d3554",
   "metadata": {},
   "source": [
    "# Spark 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d9cee4-6191-4806-ae9d-f5cdf47470d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from seaborn import load_dataset\n",
    "from pydataset import data\n",
    "from vega_datasets import data as vega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035133ca-126d-405f-9f73-ab75aabd2ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/18 10:29:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3630e78-bd02-4ddd-b8be-c35039ad4a31",
   "metadata": {},
   "source": [
    "### 1. Create & Explore a DF\n",
    "Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f1a627-82e4-4b5f-92d9-073c1899a779",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25a753-b23f-4aaf-a0b7-68fc114d14f1",
   "metadata": {},
   "source": [
    "#### Create DF\n",
    "The name of the column should be language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c01c150-7c09-4219-9ec0-d973b8145272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DF with column name of language\n",
    "\n",
    "pandas_df = pd.DataFrame(data=['JavaScript', 'Java', 'C#', 'C', 'C++',\\\n",
    "                               'Go', 'PHP','Python', 'R', 'Swift'], columns=['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80e29ca-d7b3-44af-854a-04f3d05c2f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[language: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the pandas DF to a Spark dataframe\n",
    "df = spark.createDataFrame(pandas_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52766ae1-dfed-433e-9fcc-81601f1798e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  language|\n",
      "+----------+\n",
      "|JavaScript|\n",
      "|      Java|\n",
      "|        C#|\n",
      "|         C|\n",
      "|       C++|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ef8814-1b09-4130-b9b2-2a4382677584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|summary|language|\n",
      "+-------+--------+\n",
      "|  count|      10|\n",
      "|   mean|    null|\n",
      "| stddev|    null|\n",
      "|    min|       C|\n",
      "|    max|   Swift|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8568f3-4855-4976-9b5b-9c0c0e99853d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d320e8-6118-4d06-a99c-40d55cdb384c",
   "metadata": {},
   "source": [
    "#### View Schema\n",
    "View the schema of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3b0492-8e68-420a-b98d-abf91c77a083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the schema of the dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865b19c-0ea5-4d34-af68-bc1cbcc55ec4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812574c1-4fe5-4f6d-a4e3-10e864e2859e",
   "metadata": {},
   "source": [
    "#### Shape\n",
    "Output the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03a09cd-ce57-48a1-ad07-8f2d5e1596bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 rows 1 columns\n"
     ]
    }
   ],
   "source": [
    "# Output the shape of the dataframe\n",
    "print(df.count(), \"rows\", len(df.columns), \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82712f9-60ef-4e3c-8125-e31527d552d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eed406-c184-4a7a-99b5-24928a307d68",
   "metadata": {},
   "source": [
    "#### First 5 Records\n",
    "Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa1b49ee-f685-43b9-be7d-21aef27be3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(language='JavaScript'),\n",
       " Row(language='Java'),\n",
       " Row(language='C#'),\n",
       " Row(language='C'),\n",
       " Row(language='C++')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the first 5 records in the dataframe\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c8733a-7c6e-4f72-a294-bf071245ef23",
   "metadata": {},
   "source": [
    "## 2. MPG\n",
    "Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "- 2a. \n",
    "Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "For each vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f28bbe-bf28-4c82-9c90-a40f90e5b7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24b2c7d2-9660-49ce-bf45-629d58bfbedf",
   "metadata": {},
   "source": [
    "- 2b. \n",
    "Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f771fa-4c9d-4dcf-84cd-0047a731ef78",
   "metadata": {},
   "source": [
    "3. Load the tips dataset as a spark dataframe.\n",
    "\n",
    "- 3a. \n",
    "What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840fda3b-99e5-48b9-8f9d-16eb3b878ee2",
   "metadata": {},
   "source": [
    "- 3b.\n",
    "Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e461a6-4c62-492a-b757-40ff744b34b8",
   "metadata": {},
   "source": [
    "- 3c. \n",
    "Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d13f7e-fe8d-4ede-aa11-2a23922a44e3",
   "metadata": {},
   "source": [
    "4. Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to fahrenheit.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
