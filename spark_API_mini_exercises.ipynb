{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591accf3-5e2e-4db9-a1fe-b168a336df9c",
   "metadata": {},
   "source": [
    "## Spark Mini Lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a77f97-97d0-4784-8458-1cb5b1e965c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68132bf4-b89d-499f-8ad4-9405fba80fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame(\n",
    "    {\n",
    "        \"n\": np.random.randn(20),\n",
    "        \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "        \"abool\": np.random.choice([True, False], 20),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154da5d-aed7-40ec-bc96-98f28d0784eb",
   "metadata": {},
   "source": [
    "## 1. Spark Dataframe Basics\n",
    "\n",
    "### a. \n",
    "Use the starter code above to create a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb0850e7-fd29-428f-9ec1-48cde008fddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>group</th>\n",
       "      <th>abool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.712391</td>\n",
       "      <td>z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753766</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.044503</td>\n",
       "      <td>z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.451812</td>\n",
       "      <td>y</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.345102</td>\n",
       "      <td>z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n group  abool\n",
       "0 -0.712391     z  False\n",
       "1  0.753766     x  False\n",
       "2 -0.044503     z  False\n",
       "3  0.451812     y  False\n",
       "4  1.345102     z  False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77430a84-f7f1-4467-800d-667614db888d",
   "metadata": {},
   "source": [
    "### b. \n",
    "Convert the pandas dataframe to a spark dataframe. From this point forward, do all of your work with the spark dataframe, not the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc45eca-cb43-4985-b531-130b6b3029de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "853dfa3a-aebc-4725-a771-f2687307d506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/18 10:48:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/18 10:48:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dccbb183-8b89-4358-a45a-01b7c323d1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[n: double, group: string, abool: boolean]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the pandas DF to a Spark dataframe\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33071d7d-4005-4f6b-af09-e7b1e67ab451",
   "metadata": {},
   "source": [
    "### c. \n",
    "Show the first 3 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e71085f-1f9d-4aab-8499-d31b14a33278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45008ea4-60b5-40de-834a-4f103d2be500",
   "metadata": {},
   "source": [
    "### d. \n",
    "Show the first 7 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "442b8302-940c-4526-a73b-e7e5a328e1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b39138-33e8-49bd-9e01-5efe974a1445",
   "metadata": {},
   "source": [
    "### e. \n",
    "What is the difference between .show and .head?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be43ca1-26cb-41ce-9fc5-d9a2a22302bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d91f5e81-8225-4624-bcbd-d9a2ce1ed1e0",
   "metadata": {},
   "source": [
    "### f. \n",
    "View a summary of the data using .describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa4f86-1282-4586-92ac-79c2404b14c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3284d595-e5bd-4f24-9e75-e20e0bba4157",
   "metadata": {},
   "source": [
    "### g. \n",
    "Use .select to create a new dataframe with just the n and abool columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135a57f-4568-4661-8b90-9b0400dbfa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d362d7d2-5320-422e-8ebe-10af5c1a543a",
   "metadata": {},
   "source": [
    "### h. \n",
    "Use .select to create a new dataframe with just the group and abool columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d5f2c-deff-4684-be16-2caf022b697b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "893530e3-0e52-43f1-862b-303f497843dc",
   "metadata": {},
   "source": [
    "### i. \n",
    "Use .select to create a new dataframe with the group column and the abool column renamed to a_boolean_value. Show the first 3 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c79e17-347c-4872-9039-36fcf95e6fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ede12aaa-17fd-434e-b44d-f9cba1f6c0ae",
   "metadata": {},
   "source": [
    "### j. \n",
    "Use .select to create a new dataframe with the group column and the n column renamed to a_numeric_value. Show the first 6 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c69ec-e321-4705-9a2b-09c6b67a1e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de763e16-212e-469d-9385-35c9ac1621a4",
   "metadata": {},
   "source": [
    "## 2. Column Manipulation\n",
    "\n",
    "### a. \n",
    "Use the starter code above to re-create a spark dataframe. Store the spark dataframe in a varaible named df\n",
    "\n",
    "### b. \n",
    "Use .select to add 4 to the n column. Show the results.\n",
    "\n",
    "### c. \n",
    "Subtract 5 from the n column and view the results.\n",
    "\n",
    "### d. \n",
    "Multiply the n column by 2. View the results along with the original numbers.\n",
    "\n",
    "### e. \n",
    "Add a new column named n2 that is the n value multiplied by -1. Show the first 4 rows of your dataframe. You should see the original n value as well as n2.\n",
    "\n",
    "### f. \n",
    "Add a new column named n3 that is the n value squared. Show the first 5 rows of your dataframe. You should see both n, n2, and n3.\n",
    "\n",
    "### g. \n",
    "What happens when you run the code below?\n",
    "\n",
    "df.group + df.abool\n",
    "\n",
    "### h. \n",
    "What happens when you run the code below? What is the difference between this and the previous code sample?\n",
    "\n",
    "df.select(df.group + df.abool)\n",
    "\n",
    "### i. \n",
    "Try adding various other columns together. What are the results of combining the different data types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c55e69-a311-4ea3-84f2-9ce07b2750f0",
   "metadata": {},
   "source": [
    "## 3. Type casting\n",
    "\n",
    "### a.\n",
    "Use the starter code above to re-create a spark dataframe.\n",
    "\n",
    "### b.\n",
    "Use .printSchema to view the datatypes in your dataframe.\n",
    "\n",
    "### c. \n",
    "Use .dtypes to view the datatypes in your dataframe.\n",
    "\n",
    "### d.\n",
    "What is the difference between the two code samples below?\n",
    "\n",
    "df.abool.cast('int')\n",
    "df.select(df.abool.cast('int')).show()\n",
    "\n",
    "### e.\n",
    "Use .select and .cast to convert the abool column to an integer type. View the results.\n",
    "\n",
    "### f. \n",
    "Convert the group column to a integer data type and view the results. What happens?\n",
    "\n",
    "### g. \n",
    "Convert the n column to a integer data type and view the results. What happens?\n",
    "\n",
    "### h.\n",
    "Convert the abool column to a string data type and view the results. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b59d09-19ae-4d78-832e-55ac157f7c5b",
   "metadata": {},
   "source": [
    "4. Built-in Functions\n",
    "\n",
    "Use the starter code above to re-create a spark dataframe.\n",
    "Import the necessary functions from pyspark.sql.functions\n",
    "Find the highest n value.\n",
    "Find the lowest n value.\n",
    "Find the average n value.\n",
    "Use concat to change the group column to say, e.g. \"Group: x\" or \"Group: y\"\n",
    "Use concat to combine the n and group columns to produce results that look like this: \"x: -1.432\" or \"z: 2.352\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887f74c-d910-46fd-86ad-3e273fc45748",
   "metadata": {},
   "source": [
    "5. When / Otherwise\n",
    "\n",
    "Use the starter code above to re-create a spark dataframe.\n",
    "Use when and .otherwise to create a column that contains the text \"It is true\" when abool is true and \"It is false\"\" when abool is false.\n",
    "Create a column that contains 0 if n is less than 0, otherwise, the original n value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ccfc6-d03b-41d1-a80e-2e96072e1d01",
   "metadata": {},
   "source": [
    "6. Filter / Where\n",
    "\n",
    "Use the starter code above to re-create a spark dataframe.\n",
    "Use .filter or .where to select just the rows where the group is y and view the results.\n",
    "Select just the columns where the abool column is false and view the results.\n",
    "Find the columns where the group column is not y.\n",
    "Find the columns where n is positive.\n",
    "Find the columns where abool is true and the group column is z.\n",
    "Find the columns where abool is true or the group column is z.\n",
    "Find the columns where abool is false and n is less than 1\n",
    "Find the columns where abool is false or n is less than 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e1233-f373-4c1b-87aa-facee6f369a2",
   "metadata": {},
   "source": [
    "7. Sorting\n",
    "\n",
    "Use the starter code above to re-create a spark dataframe.\n",
    "Sort by the n value.\n",
    "Sort by the group value, both ascending and descending.\n",
    "Sort by the group value first, then, within each group, sort by n value.\n",
    "Sort by abool, group, and n. Does it matter in what order you specify the columns when sorting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50872552-42c8-43a7-afca-3d3083eacff4",
   "metadata": {},
   "source": [
    "8. Aggregating\n",
    "\n",
    "What is the average n value for each group in the group column?\n",
    "What is the maximum n value for each group in the group column?\n",
    "What is the minimum n value by abool?\n",
    "What is the average n value for each unique combination of the group and abool column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a2486-16f3-4579-8662-8e9e4c2f0a72",
   "metadata": {},
   "source": [
    "9. Spark SQL\n",
    "\n",
    "Use the starter code above to re-create a spark dataframe.\n",
    "Turn your dataframe into a table that can be queried with spark SQL. Name the table my_df. Answer the rest of the questions in this section with a spark sql query (spark.sql) against my_df. After each step, view the first 7 records from the dataframe.\n",
    "What happens if you make a SQL syntax error in your query?\n",
    "Write a query that shows all of the columns from your dataframe.\n",
    "Write a query that shows just the n and abool columns from the dataframe.\n",
    "Write a query that shows just the n and group columns. Rename the group column to g.\n",
    "Write a query that selects n, and creates two new columns: n2, the original n values halved, and n3: the original n values minus 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86005123-560d-4e29-928d-242da402df67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c174e0-b7da-469c-a4ca-3f2a99ff1ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66edc19-ae81-4cfd-a11a-3daff0c9d30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
